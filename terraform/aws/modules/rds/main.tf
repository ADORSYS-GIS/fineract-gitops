terraform {
  required_version = ">= 1.5"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

# Local values for dynamic parameter calculation
locals {
  # Map instance classes to memory in MB
  # Based on AWS RDS instance specifications
  instance_memory_mb = {
    "db.t3.micro"    = 1024    # 1 GB
    "db.t3.small"    = 2048    # 2 GB
    "db.t3.medium"   = 4096    # 4 GB
    "db.t3.large"    = 8192    # 8 GB
    "db.t3.xlarge"   = 16384   # 16 GB
    "db.t3.2xlarge"  = 32768   # 32 GB
    "db.t4g.micro"   = 1024    # 1 GB
    "db.t4g.small"   = 2048    # 2 GB
    "db.t4g.medium"  = 4096    # 4 GB
    "db.t4g.large"   = 8192    # 8 GB
    "db.t4g.xlarge"  = 16384   # 16 GB
    "db.t4g.2xlarge" = 32768   # 32 GB
    "db.m5.large"    = 8192    # 8 GB
    "db.m5.xlarge"   = 16384   # 16 GB
    "db.m5.2xlarge"  = 32768   # 32 GB
    "db.m5.4xlarge"  = 65536   # 64 GB
    "db.m5.8xlarge"  = 131072  # 128 GB
    "db.m6g.large"   = 8192    # 8 GB
    "db.m6g.xlarge"  = 16384   # 16 GB
    "db.m6g.2xlarge" = 32768   # 32 GB
    "db.m6g.4xlarge" = 65536   # 64 GB
    "db.r5.large"    = 16384   # 16 GB
    "db.r5.xlarge"   = 32768   # 32 GB
    "db.r5.2xlarge"  = 65536   # 64 GB
    "db.r5.4xlarge"  = 131072  # 128 GB
  }

  # Calculate memory-based parameters
  instance_memory    = lookup(local.instance_memory_mb, var.instance_class, 4096)
  shared_buffers_kb  = floor(local.instance_memory * 1024 / 4)  # 25% of RAM
  effective_cache_kb = floor(local.instance_memory * 1024 / 2)  # 50% of RAM
  work_mem_kb        = min(32768, floor(local.instance_memory * 1024 / 100))  # ~1% of RAM, max 32MB

  # Calculate max_connections based on instance memory
  # Formula: max_connections = (RAM_MB - 256) / 10, with min 20 and max 5000
  calculated_max_connections = max(20, min(5000, floor((local.instance_memory - 256) / 10)))
  max_connections            = var.max_connections != null ? var.max_connections : local.calculated_max_connections
}

# DB Subnet Group
resource "aws_db_subnet_group" "fineract" {
  name       = "${var.cluster_name}-${var.environment}-fineract-db"
  subnet_ids = var.subnet_ids

  tags = merge(
    var.tags,
    {
      Name        = "${var.cluster_name}-${var.environment}-fineract-db"
      Environment = var.environment
      Component   = "database"
    }
  )
}

# Security Group for RDS
resource "aws_security_group" "rds" {
  name        = "${var.cluster_name}-${var.environment}-rds-sg"
  description = "Security group for Fineract RDS PostgreSQL"
  vpc_id      = var.vpc_id

  ingress {
    description     = "PostgreSQL from EKS"
    from_port       = 5432
    to_port         = 5432
    protocol        = "tcp"
    security_groups = var.allowed_security_groups
  }

  egress {
    description = "Allow all outbound"
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = merge(
    var.tags,
    {
      Name        = "${var.cluster_name}-${var.environment}-rds-sg"
      Environment = var.environment
    }
  )
}

# RDS Password Management Strategy
# ============================================================================
# CURRENT APPROACH: random_password + Terraform state
# - Password generated by Terraform and stored in state file
# - State file stored in S3 with encryption at rest
# - Password NOT in ignore_changes (can be rotated via Terraform)
#
# SECURITY TRADE-OFFS:
# - Pro: GitOps-friendly, version-controlled infrastructure
# - Pro: Automated password generation and rotation
# - Con: Password stored in Terraform state (S3 encrypted)
# - Con: Anyone with state file access can read password
# - Mitigation: S3 bucket encryption, IAM policies, state locking
#
# PRODUCTION-GRADE ALTERNATIVES:
# 1. AWS Secrets Manager with Rotation (RECOMMENDED):
#    resource "aws_secretsmanager_secret" "rds_password" {
#      name = "${var.cluster_name}-${var.environment}-rds-master-password"
#      rotation_rules {
#        automatically_after_days = 30
#      }
#    }
#    resource "aws_secretsmanager_secret_version" "rds_password" {
#      secret_id     = aws_secretsmanager_secret.rds_password.id
#      secret_string = random_password.master.result
#    }
#    Then: password = data.aws_secretsmanager_secret_version.rds_password.secret_string
#    Pros: Automatic rotation, audit trail, no password in state
#    Cons: Additional AWS cost, complexity
#
# 2. External Password Management (Manual):
#    - Generate password outside Terraform
#    - Store in Secrets Manager manually
#    - Reference via data source
#    - Pros: Password never in Terraform state
#    - Cons: Not fully automated, manual rotation
#
# 3. KMS-encrypted Parameter Store:
#    resource "aws_ssm_parameter" "rds_password" {
#      name   = "/${var.cluster_name}/${var.environment}/rds/master-password"
#      type   = "SecureString"
#      value  = random_password.master.result
#      key_id = var.kms_key_id
#    }
#    Similar trade-offs to Secrets Manager
#
# PASSWORD ROTATION PROCEDURE:
# Current approach:
#   1. terraform taint random_password.master
#   2. terraform apply (generates new password, updates RDS)
#   3. Update sealed secrets in Git
#   4. ArgoCD syncs new credentials to Kubernetes
# With Secrets Manager:
#   - Automatic rotation with Lambda function
#   - No manual steps needed
#
# CURRENT JUSTIFICATION:
# - Acceptable for: Dev, staging, cost-sensitive environments
# - Consider Secrets Manager for: Production, compliance requirements, automated rotation
# - Risk mitigation: Encrypted state, IAM policies, regular rotation schedule
#
# Random password for master user
resource "random_password" "master" {
  length           = 32
  special          = true
  override_special = "!#$%&*()-_=+[]{}<>:?"
}

# RDS PostgreSQL Instance
resource "aws_db_instance" "fineract" {
  identifier = "${var.cluster_name}-${var.environment}-fineract"

  # Engine
  engine         = "postgres"
  engine_version = var.postgres_version

  # Instance
  instance_class        = var.instance_class
  allocated_storage     = var.allocated_storage
  max_allocated_storage = var.max_allocated_storage
  storage_type          = var.storage_type
  storage_encrypted     = true
  kms_key_id            = var.kms_key_id

  # Database - no default database created
  # Applications create their own databases via Kubernetes jobs
  username = var.master_username
  password = random_password.master.result
  port     = 5432

  # Network
  db_subnet_group_name   = aws_db_subnet_group.fineract.name
  vpc_security_group_ids = [aws_security_group.rds.id]
  publicly_accessible    = false

  # High Availability
  multi_az          = var.multi_az
  availability_zone = var.multi_az ? null : var.availability_zone

  # Backup
  backup_retention_period = var.backup_retention_period
  backup_window           = var.backup_window
  maintenance_window      = var.maintenance_window
  # Final snapshot naming without timestamp to avoid constant changes
  # Terraform will error if snapshot name already exists, forcing manual cleanup
  final_snapshot_identifier = "${var.cluster_name}-${var.environment}-fineract-final"
  skip_final_snapshot       = var.skip_final_snapshot
  copy_tags_to_snapshot     = true

  # Performance Insights
  performance_insights_enabled          = var.performance_insights_enabled
  performance_insights_kms_key_id       = var.kms_key_id
  performance_insights_retention_period = var.performance_insights_enabled ? 7 : null

  # Enhanced Monitoring - Disabled (CloudWatch removed)
  enabled_cloudwatch_logs_exports = []
  monitoring_interval             = 0
  monitoring_role_arn             = null

  # Parameters
  parameter_group_name = aws_db_parameter_group.fineract.name

  # Maintenance
  auto_minor_version_upgrade = var.auto_minor_version_upgrade
  deletion_protection        = var.deletion_protection

  tags = merge(
    var.tags,
    {
      Name        = "${var.cluster_name}-${var.environment}-fineract"
      Environment = var.environment
      Component   = "database"
    }
  )

  lifecycle {
    ignore_changes = [
      # Keep final_snapshot_identifier in ignore_changes to prevent unnecessary updates
      final_snapshot_identifier
    ]
    # Note: password is NOT in ignore_changes
    # If you need to rotate the password, update it in AWS Secrets Manager
    # and then update the Terraform configuration
  }
}

# Parameter Group
resource "aws_db_parameter_group" "fineract" {
  name   = "${var.cluster_name}-${var.environment}-fineract-pg"
  family = "postgres${split(".", var.postgres_version)[0]}"

  # Performance tuning for Fineract - dynamically calculated based on instance class
  parameter {
    name         = "shared_buffers"
    value        = tostring(local.shared_buffers_kb) # 25% of RAM
    apply_method = "pending-reboot"
  }

  parameter {
    name         = "effective_cache_size"
    value        = tostring(local.effective_cache_kb) # 50% of RAM
    apply_method = "pending-reboot"
  }

  parameter {
    name         = "maintenance_work_mem"
    value        = "2097152" # 2GB (static, suitable for most instances)
    apply_method = "pending-reboot"
  }

  parameter {
    name         = "work_mem"
    value        = tostring(local.work_mem_kb) # ~1% of RAM, max 32MB
    apply_method = "pending-reboot"
  }

  parameter {
    name         = "max_connections"
    value        = tostring(local.max_connections) # Dynamically calculated or user-provided
    apply_method = "pending-reboot"
  }

  parameter {
    name         = "random_page_cost"
    value        = "1.1" # SSD optimization
    apply_method = "pending-reboot"
  }

  parameter {
    name         = "effective_io_concurrency"
    value        = "200" # SSD optimization
    apply_method = "pending-reboot"
  }

  parameter {
    name         = "wal_buffers"
    value        = "16384" # 16MB
    apply_method = "pending-reboot"
  }

  parameter {
    name         = "checkpoint_completion_target"
    value        = "0.9"
    apply_method = "pending-reboot"
  }

  parameter {
    name         = "log_min_duration_statement"
    value        = var.log_slow_queries ? "1000" : "-1" # Log queries > 1s
    apply_method = "pending-reboot"
  }

  tags = merge(
    var.tags,
    {
      Name        = "${var.cluster_name}-${var.environment}-fineract-pg"
      Environment = var.environment
    }
  )
}

# IAM Role for Enhanced Monitoring
resource "aws_iam_role" "rds_monitoring" {
  count = var.monitoring_interval > 0 ? 1 : 0
  name  = "${var.cluster_name}-${var.environment}-rds-monitoring"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Action = "sts:AssumeRole"
        Effect = "Allow"
        Principal = {
          Service = "monitoring.rds.amazonaws.com"
        }
      }
    ]
  })

  tags = merge(
    var.tags,
    {
      Name        = "${var.cluster_name}-${var.environment}-rds-monitoring"
      Environment = var.environment
    }
  )
}

resource "aws_iam_role_policy_attachment" "rds_monitoring" {
  count      = var.monitoring_interval > 0 ? 1 : 0
  role       = aws_iam_role.rds_monitoring[0].name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AmazonRDSEnhancedMonitoringRole"
}

# ============================================================================
# Keycloak Database and User Setup
# ============================================================================

# Random password for Keycloak database user
resource "random_password" "keycloak" {
  length           = 32
  special          = true
  override_special = "!#$%&*()-_=+[]{}<>:?"
}

# KEYCLOAK DATABASE USER CREATION STRATEGY:
# Current approach: Kubernetes Job (create-keycloak-db-job.yaml)
# See: operations/database-setup/create-keycloak-db-job.yaml
#
# RATIONALE:
# - Runs inside VPC with network access to RDS (no bastion needed)
# - No psql dependency on Terraform execution machine
# - Idempotent: Safe to re-run
# - Observable: Logs visible in Kubernetes
# - GitOps-aligned: Job definition in version control
#
# ALTERNATIVE APPROACHES:
# 1. Terraform null_resource with local-exec (NOT RECOMMENDED):
#    resource "null_resource" "keycloak_db" {
#      provisioner "local-exec" {
#        command = "psql -h ${aws_db_instance.fineract.endpoint} ..."
#      }
#    }
#    Cons: Requires psql locally, network access issues, not idempotent
#
# 2. AWS Lambda Function (RECOMMENDED for production):
#    - Lambda in VPC with RDS access
#    - Triggered via Custom Resource in Terraform
#    - Idempotent with state management
#    - Example:
#      resource "aws_lambda_function" "db_setup" { ... }
#      resource "null_resource" "trigger_lambda" {
#        provisioner "local-exec" {
#          command = "aws lambda invoke ..."
#        }
#      }
#    Pros: Fully automated, no Kubernetes dependency, AWS-native
#    Cons: Additional Lambda code, more complex
#
# 3. Terraform PostgreSQL Provider:
#    provider "postgresql" {
#      host     = aws_db_instance.fineract.endpoint
#      username = var.master_username
#      password = random_password.master.result
#    }
#    resource "postgresql_database" "keycloak" {
#      name = "keycloak"
#    }
#    resource "postgresql_role" "keycloak" {
#      name     = "keycloak"
#      password = random_password.keycloak.result
#    }
#    Pros: Declarative, idempotent, Terraform-native
#    Cons: Requires network access from Terraform machine, credentials in state
#
# CURRENT APPROACH JUSTIFICATION:
# - Best for: Kubernetes-centric deployments, GitOps workflows
# - Works when: RDS is private, no bastion setup yet
# - Consider Lambda for: Pure Terraform workflows, production automation
# - Consider PostgreSQL provider for: Direct network access available
#
# The password generated here is retrieved via Terraform outputs and sealed
# into Kubernetes secrets using the seal-terraform-secrets.sh script.
